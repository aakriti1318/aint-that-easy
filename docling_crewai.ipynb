{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import LLM, Agent, Task, Crew, Process\n",
    "from IPython.display import Markdown\n",
    "from crewai.knowledge.source.crew_docling_source import CrewDoclingSource\n",
    "from dotenv import load_dotenv\n",
    "from composio_crewai import Action, App, ComposioToolSet\n",
    "from typing import Dict\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = os.path.abspath(\"nda.txt\")\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize knowledge source\n",
    "content_source = CrewDoclingSource(\n",
    "    file_paths=[\"...\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM setup\n",
    "WATSONX_MODEL_ID = \"watsonx/meta-llama/llama-3-8b-instruct\"\n",
    "parameters = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"max_new_tokens\": 1000,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 1,\n",
    "    \"repetition_penalty\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model=WATSONX_MODEL_ID,\n",
    "    parameters=parameters,\n",
    "    max_tokens=1000,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-01-11 17:49:26,071][INFO] Actions cache is outdated, refreshing cache...\n"
     ]
    }
   ],
   "source": [
    "# Toolset initialization\n",
    "tool_set = ComposioToolSet()\n",
    "rag_tools = tool_set.get_tools(\n",
    "    apps=[App.RAGTOOL],\n",
    "    actions=[\n",
    "        Action.FILETOOL_LIST_FILES,\n",
    "        Action.FILETOOL_CHANGE_WORKING_DIRECTORY,\n",
    "        Action.FILETOOL_FIND_FILE,\n",
    "    ]\n",
    ")\n",
    "rag_query_tools = tool_set.get_tools(apps=[App.RAGTOOL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic models for output\n",
    "class AgentOutput(BaseModel):\n",
    "    \"\"\"Output of each clause agent\"\"\"\n",
    "    analysis: str = Field(description=\"An analysis of the section in laymen terms\")\n",
    "    recommendation: str = Field(\n",
    "        description=\"How the current clause deviates from the benchmark documents\"\n",
    "    )\n",
    "\n",
    "\n",
    "class FinalOutput(BaseModel):\n",
    "    data: Dict[str, AgentOutput]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agents\n",
    "corporate_lawyer_agent = Agent(\n",
    "    role=\"Corporate Lawyer\",\n",
    "    goal=\"Ingest NDAs and build a robust knowledge base for comparing NDA clauses.\",\n",
    "    backstory=\"\"\"You are a seasoned corporate lawyer specializing in NDAs. Your expertise lies in identifying best practices \n",
    "    and deviations across various clauses. You have access to tools to ingest and query relevant documents.\"\"\",\n",
    "    # tools=rag_tools,\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "clause_analysis_agent = Agent(\n",
    "    role=\"Clause Analysis Specialist\",\n",
    "    goal=\"Analyze and evaluate NDA clauses against benchmark documents.\",\n",
    "    backstory=\"\"\"You are an expert in evaluating NDA clauses, ensuring they align with legal best practices. \n",
    "    Your attention to detail allows you to identify gaps and improvements across all key sections of NDAs.\"\"\",\n",
    "    # tools=rag_query_tools,\n",
    "    verbose=True,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task templates\n",
    "EXPECTED_TASK_OUTPUT = \"\"\"\n",
    "A JSON that has two keys: an `analysis` of the current clause in laymen terms as a paragraph as well as a `recommendation` of how the current clause deviates from the benchmark clauses (in short, numbered points).\"\"\"\n",
    "\n",
    "\n",
    "def create_accumulating_task(original_task, key):\n",
    "    def accumulating_task(agent, context):\n",
    "        result = original_task.function(agent, context)\n",
    "        if \"accumulated_results\" not in context:\n",
    "            context[\"accumulated_results\"] = {}\n",
    "        context[\"accumulated_results\"][key] = result\n",
    "        return context[\"accumulated_results\"]\n",
    "\n",
    "    return Task(\n",
    "        description=original_task.description,\n",
    "        agent=original_task.agent,\n",
    "        function=accumulating_task,\n",
    "        expected_output=original_task.expected_output,\n",
    "        output_pydantic=original_task.output_pydantic,\n",
    "        context=original_task.context,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks(input_document):\n",
    "    tasks = []\n",
    "\n",
    "    # Task: Ingest benchmark NDAs\n",
    "    ingest_documents_task = Task(\n",
    "        description=\"\"\"Ingest benchmark NDAs for comparison. Check all files in the 'ndas' folder \n",
    "        with 'docx', 'doc', or 'pdf' extensions and ingest them using the RAG tool.\"\"\",\n",
    "        expected_output=EXPECTED_TASK_OUTPUT,\n",
    "        agent=corporate_lawyer_agent,\n",
    "    )\n",
    "    tasks.append(create_accumulating_task(ingest_documents_task, \"ingest_documents\"))\n",
    "\n",
    "    # General clause analysis task\n",
    "    clauses = [\n",
    "        (\"Parties Clause\", \"identify_parties\"),\n",
    "        (\"Obligations of Receiving Party\", \"obligations\"),\n",
    "        (\"Terms and Termination\", \"terms_and_termination\"),\n",
    "        (\"Remedies Clause\", \"remedies\"),\n",
    "        (\"Additional Information\", \"additional_info\"),\n",
    "    ]\n",
    "\n",
    "    for clause_name, key in clauses:\n",
    "        task = Task(\n",
    "            description=f\"\"\"Analyze the {clause_name} in the document: `{input_document}`. \n",
    "            Compare it to similar clauses in our database and identify how well it aligns with legal best practices.\"\"\",\n",
    "            expected_output=EXPECTED_TASK_OUTPUT,\n",
    "            agent=clause_analysis_agent,\n",
    "            output_pydantic=AgentOutput,\n",
    "        )\n",
    "        tasks.append(create_accumulating_task(task, key))\n",
    "\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crew setup\n",
    "def get_crew(input_doc):\n",
    "    crew = Crew(\n",
    "        agents=[corporate_lawyer_agent, clause_analysis_agent],\n",
    "        tasks=get_tasks(input_doc),\n",
    "        knowledge_sources=[content_source],\n",
    "        process=Process.sequential,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute the crew and get results\n",
    "def get_agent_output(document):\n",
    "    crew = get_crew(document)\n",
    "    result = crew.kickoff()\n",
    "\n",
    "    if isinstance(result, dict) and \"accumulated_results\" in result:\n",
    "        return result[\"accumulated_results\"]\n",
    "    else:\n",
    "        return {\"final_recommendation\": result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_agent_output(\"https://docs.google.com/document/d/117dEIoTJQEEQlrBHPYBiG3ZqjEmL_HFd/edit?usp=sharing&ouid=110583291928749264455&rtpof=true&sd=true\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\n",
       "  \"analysis\": \"The Additional Information clause in the provided NDA document lacks specifics regarding the confidentiality obligation, fails to define critical terms, and does not address the method of data destruction or return of intellectual property upon termination. It also neglects to detail the procedure for dealing with potential disputes, breaches, or disagreements between parties. The clause should be revised to provide clear guidelines for handling sensitive information, defining key terms, and outlining procedures for data destruction, return of intellectual property, and dispute resolution.\",\n",
       "  \"recommendation\": [\n",
       "    1. \"Specify the method and scope of data destruction or return of intellectual property upon termination to ensure compliance with confidentiality obligations and avoid potential disputes.\",\n",
       "    2. \"Define critical terms such as 'Confidential Information' and 'Intellectual Property' to establish a clear understanding of what is protected.\",\n",
       "    3. \"Outline procedures for dealing with potential disputes, breaches, or disagreements between parties, including methods for notification, resolution, and conflict resolution.\",\n",
       "    4. \"Establish consequences for failure to comply with confidentiality obligations, including damages or legal action, to strengthen the clause's effectiveness.\",\n",
       "    5. \"Address the method of notice delivery to ensure receipt and proof of delivery in relation to termination or dispute resolution.\"\n",
       "  ]\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "result_str = str(result['final_recommendation']) \n",
    "\n",
    "Markdown(result_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
